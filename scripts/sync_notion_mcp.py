#!/usr/bin/env python3
"""
Notionå·®åˆ†åŒæœŸã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆé«˜é€Ÿç‰ˆï¼‰
- æœ€çµ‚åŒæœŸæ—¥æ™‚ä»¥é™ã«æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã®ã¿å–å¾—
- æ›´æ–°æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆã—ã¦åŠ¹ç‡çš„ã«å·®åˆ†æ¤œå‡º
"""

import os
import json
import sys
from datetime import datetime, timezone
from pathlib import Path
import time
import requests

# ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç„¡åŠ¹
sys.stdout.reconfigure(line_buffering=True)

# è¨­å®š
NOTION_API_TOKEN = os.environ.get('NOTION_API_TOKEN', '')
SCRIPT_DIR = Path(__file__).parent.resolve()
PROJECT_DIR = SCRIPT_DIR.parent
NOTION_DOCS_DIR = PROJECT_DIR / 'notion_docs'
SYNC_STATE_FILE = PROJECT_DIR / '.notion_sync_state.json'
HEADERS = {
    'Authorization': f'Bearer {NOTION_API_TOKEN}',
    'Notion-Version': '2022-06-28',
    'Content-Type': 'application/json'
}

def load_sync_state():
    """å‰å›ã®åŒæœŸçŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€"""
    if SYNC_STATE_FILE.exists():
        with open(SYNC_STATE_FILE, 'r') as f:
            return json.load(f)
    return {'last_sync': None, 'pages': {}}

def save_sync_state(state):
    """åŒæœŸçŠ¶æ…‹ã‚’ä¿å­˜"""
    state['last_sync'] = datetime.now(timezone.utc).isoformat()
    with open(SYNC_STATE_FILE, 'w') as f:
        json.dump(state, f, indent=2, ensure_ascii=False)

def search_recent_pages(last_sync_time=None):
    """æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆæ›´æ–°æ—¥æ™‚é †ï¼‰"""
    print("[API] æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’å–å¾—ä¸­...", flush=True)
    all_results = []
    start_cursor = None

    while True:
        payload = {
            'page_size': 100,
            'sort': {
                'direction': 'descending',
                'timestamp': 'last_edited_time'
            },
            'filter': {
                'property': 'object',
                'value': 'page'
            }
        }
        if start_cursor:
            payload['start_cursor'] = start_cursor

        try:
            response = requests.post(
                'https://api.notion.com/v1/search',
                headers=HEADERS,
                json=payload,
                timeout=60
            )
        except Exception as e:
            print(f"  Error: {e}", flush=True)
            break

        if response.status_code != 200:
            print(f"  API Error: {response.status_code}", flush=True)
            break

        data = response.json()
        results = data.get('results', [])

        # æœ€çµ‚åŒæœŸæ—¥æ™‚ã‚ˆã‚Šå¤ã„ãƒšãƒ¼ã‚¸ãŒå‡ºã¦ããŸã‚‰çµ‚äº†
        found_old = False
        for page in results:
            last_edited = page.get('last_edited_time', '')
            if last_sync_time and last_edited < last_sync_time:
                found_old = True
                break
            all_results.append(page)

        print(f"  å–å¾—: {len(all_results)}ä»¶...", flush=True)

        if found_old:
            print(f"  â†’ å‰å›åŒæœŸä»¥å‰ã®ãƒšãƒ¼ã‚¸ã«åˆ°é”ã€æ¤œç´¢çµ‚äº†", flush=True)
            break

        if not data.get('has_more'):
            break
        start_cursor = data.get('next_cursor')
        time.sleep(0.3)

    return all_results

def get_page_title(page):
    """ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—"""
    props = page.get('properties', {})
    for prop_name, prop_value in props.items():
        if prop_value.get('type') == 'title':
            title_list = prop_value.get('title', [])
            if title_list:
                return ''.join([t.get('plain_text', '') for t in title_list])
    return 'Untitled'

def get_page_content(page_id):
    """ãƒšãƒ¼ã‚¸ã®ãƒ–ãƒ­ãƒƒã‚¯å†…å®¹ã‚’å–å¾—"""
    blocks = []
    start_cursor = None

    while True:
        url = f'https://api.notion.com/v1/blocks/{page_id}/children'
        if start_cursor:
            url += f'?start_cursor={start_cursor}'

        try:
            response = requests.get(url, headers=HEADERS, timeout=30)
        except:
            return blocks

        if response.status_code != 200:
            return blocks

        data = response.json()
        blocks.extend(data.get('results', []))

        if not data.get('has_more'):
            break
        start_cursor = data.get('next_cursor')
        time.sleep(0.2)

    return blocks

def extract_text_from_blocks(blocks, depth=0):
    """ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    if depth > 3:  # æ·±ã™ãã‚‹å†å¸°ã‚’é˜²æ­¢
        return ""

    text_parts = []
    indent = "  " * depth

    for block in blocks:
        block_type = block.get('type', '')
        block_data = block.get(block_type, {})

        # ãƒªãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        rich_text = block_data.get('rich_text', [])
        if rich_text:
            text = ''.join([rt.get('plain_text', '') for rt in rich_text])
            if text.strip():
                text_parts.append(f"{indent}{text}")

        # å­ãƒ–ãƒ­ãƒƒã‚¯ã¯æ·±ã•åˆ¶é™å†…ã§ã®ã¿å‡¦ç†
        if block.get('has_children') and depth < 2:
            child_blocks = get_page_content(block['id'])
            child_text = extract_text_from_blocks(child_blocks, depth + 1)
            if child_text:
                text_parts.append(child_text)

    return '\n'.join(text_parts)

def sanitize_filename(name):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦å®‰å…¨ãªæ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆLinux ext4ã®255ãƒã‚¤ãƒˆåˆ¶é™å¯¾å¿œï¼‰"""
    unsafe_chars = ['/', '\\', ':', '*', '?', '"', '<', '>', '|', '\n', '\r']
    for char in unsafe_chars:
        name = name.replace(char, '_')
    # ãƒã‚¤ãƒˆæ•°ãƒ™ãƒ¼ã‚¹ã§åˆ‡ã‚Šè©°ã‚ï¼ˆext4ã¯255ãƒã‚¤ãƒˆåˆ¶é™ã€ä½™è£•ã‚’æŒã£ã¦200ãƒã‚¤ãƒˆï¼‰
    while len(name.encode('utf-8')) > 200:
        name = name[:-1]
    return name.strip()

def sync_page(page, sync_state):
    """å˜ä¸€ãƒšãƒ¼ã‚¸ã‚’åŒæœŸ"""
    page_id = page['id']
    last_edited = page.get('last_edited_time', '')
    title = get_page_title(page)

    # åŒæœŸçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
    cached = sync_state['pages'].get(page_id, {})
    if cached.get('last_edited') == last_edited:
        return False  # å¤‰æ›´ãªã—

    # ãƒšãƒ¼ã‚¸å†…å®¹ã‚’å–å¾—
    blocks = get_page_content(page_id)
    content = extract_text_from_blocks(blocks)

    # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    safe_title = sanitize_filename(title)
    if not safe_title:
        safe_title = f"page_{page_id[:8]}"
    page_dir = NOTION_DOCS_DIR / safe_title
    page_dir.mkdir(parents=True, exist_ok=True)

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    metadata = {
        'id': page_id,
        'title': title,
        'last_edited_time': last_edited,
        'url': page.get('url', ''),
        'synced_at': datetime.now(timezone.utc).isoformat()
    }
    with open(page_dir / 'metadata.json', 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¿å­˜
    with open(page_dir / 'page_content.txt', 'w', encoding='utf-8') as f:
        f.write(f"# {title}\n\n")
        f.write(f"Notion URL: {page.get('url', '')}\n")
        f.write(f"åŒæœŸæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%dT%H:%M:%S+09:00')}\n\n")
        f.write("---\n\n")
        f.write(content if content else "(ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãªã—)")

    # åŒæœŸçŠ¶æ…‹ã‚’æ›´æ–°
    sync_state['pages'][page_id] = {
        'title': title,
        'last_edited': last_edited,
        'path': str(page_dir)
    }

    return True

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("Notionå·®åˆ†åŒæœŸã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆé«˜é€Ÿç‰ˆï¼‰")
    print("=" * 60)

    if not NOTION_API_TOKEN:
        print("Error: NOTION_API_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)

    # notion_docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºä¿
    NOTION_DOCS_DIR.mkdir(parents=True, exist_ok=True)

    # åŒæœŸçŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€
    sync_state = load_sync_state()
    last_sync = sync_state.get('last_sync')

    if last_sync:
        print(f"å‰å›ã®åŒæœŸ: {last_sync}")
        print(f"â†’ {last_sync} ä»¥é™ã®æ›´æ–°ã®ã¿å–å¾—ã—ã¾ã™")
    else:
        print("åˆå›åŒæœŸã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆå…¨ãƒšãƒ¼ã‚¸å–å¾—ï¼‰")

    # æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’å–å¾—
    pages = search_recent_pages(last_sync)

    if not pages:
        print("\n[çµæœ] æ›´æ–°ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã¯ã‚ã‚Šã¾ã›ã‚“")
        save_sync_state(sync_state)
        return 0

    print(f"\n[æ¤œç´¢å®Œäº†] {len(pages)}ä»¶ã®æ›´æ–°ãƒšãƒ¼ã‚¸ã‚’ç™ºè¦‹")

    # å·®åˆ†åŒæœŸ
    updated_count = 0
    skipped_count = 0

    for i, page in enumerate(pages):
        title = get_page_title(page)

        try:
            if sync_page(page, sync_state):
                updated_count += 1
                print(f"[{i+1}/{len(pages)}] æ›´æ–°: {title[:40]}")
            else:
                skipped_count += 1
        except Exception as e:
            print(f"[{i+1}/{len(pages)}] ã‚¨ãƒ©ãƒ¼: {title[:30]} - {e}")

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        if updated_count > 0 and updated_count % 10 == 0:
            time.sleep(1)

        # 50ãƒšãƒ¼ã‚¸ã”ã¨ã«ä¸­é–“ä¿å­˜ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ï¼‰
        if (i + 1) % 50 == 0:
            save_sync_state(sync_state)
            print(f"   ğŸ’¾ ä¸­é–“ä¿å­˜: {i+1}/{len(pages)}ãƒšãƒ¼ã‚¸å®Œäº†")

    # åŒæœŸçŠ¶æ…‹ã‚’ä¿å­˜
    save_sync_state(sync_state)

    print("\n" + "=" * 60)
    print(f"âœ… åŒæœŸå®Œäº†!")
    print(f"   æ›´æ–°: {updated_count}ä»¶")
    print(f"   ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶")
    print("=" * 60)

    return updated_count

if __name__ == '__main__':
    main()
