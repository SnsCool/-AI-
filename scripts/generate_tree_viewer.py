#!/usr/bin/env python3
"""
éšå±¤æ§‹é€ ãƒ„ãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ„ãƒªãƒ¼ãƒ“ãƒ¥ãƒ¼ã‚¢HTMLã‚’ç”Ÿæˆ
"""

import re
import json

def parse_tree_txt(txt_path):
    """ãƒ„ãƒªãƒ¼å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éšå±¤æ§‹é€ ã‚’è§£æ"""
    with open(txt_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # Levela Portalã®ç›´æ¥ã®å­ã¨ãã®å­å­«ã‚’æ§‹ç¯‰
    root_children = []
    stack = [(root_children, -1)]  # (current_children_list, depth)

    for line in lines:
        # ã‚¹ã‚­ãƒƒãƒ—: ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚„ç©ºè¡Œ
        if '===' in line or 'ğŸ“' in line or not line.strip():
            continue

        # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—ï¼ˆ2ã‚¹ãƒšãƒ¼ã‚¹ã”ã¨ã«1ãƒ¬ãƒ™ãƒ«ï¼‰
        stripped = line.rstrip()
        leading_spaces = len(line) - len(line.lstrip())
        depth = leading_spaces // 2

        # ã‚¢ã‚¤ã‚³ãƒ³ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
        match = re.match(r'\s*(ğŸ“„|ğŸ“Š)\s*(.+)', stripped)
        if not match:
            continue

        icon, title = match.groups()
        node_type = 'database' if icon == 'ğŸ“Š' else 'page'
        title = title.strip()

        if not title:
            continue

        node = {'name': title, 'type': node_type, 'children': []}

        # ã‚¹ã‚¿ãƒƒã‚¯ã‚’é©åˆ‡ãªãƒ¬ãƒ™ãƒ«ã¾ã§æˆ»ã™
        while len(stack) > 1 and stack[-1][1] >= depth:
            stack.pop()

        # ç¾åœ¨ã®ãƒªã‚¹ãƒˆã«è¿½åŠ 
        stack[-1][0].append(node)

        # ã“ã®ãƒãƒ¼ãƒ‰ã®å­ãƒªã‚¹ãƒˆã‚’ã‚¹ã‚¿ãƒƒã‚¯ã«è¿½åŠ 
        stack.append((node['children'], depth))

    # ç©ºã®childrené…åˆ—ã‚’å‰Šé™¤
    def clean_empty_children(node):
        if not node.get('children'):
            if 'children' in node:
                del node['children']
        else:
            for child in node['children']:
                clean_empty_children(child)

    for node in root_children:
        clean_empty_children(node)

    return root_children


# Notionã®ç”»é¢æ§‹æˆã«åŸºã¥ã„ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†ã‘ï¼ˆã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ§‹é€ ã¨ä¸€è‡´ï¼‰
SECTIONS = {
    'Levelaå…¨ä½“': [
        'å…¨ä½“ä¼šè­°è­°äº‹éŒ²',
        'Levelaãƒ¡ãƒ³ãƒãƒ¼ç´¹ä»‹',
        'Levelaã®MVV',
        'Levelaã‚ªãƒ³ãƒ©ã‚¤ãƒ³å›³æ›¸é¤¨'
    ],
    'éƒ¨ç½²': [
        'CSéƒ¨',
        'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°éƒ¨',
        'å·¥äº‹ä¸­ğŸš§ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°éƒ¨',
        'å–¶æ¥­ãƒãƒ¼ã‚¿ãƒ«',
        'ç¤¾é•·å®¤ãƒãƒ¼ã‚¿ãƒ«',
        'ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£éƒ¨',
        'çŸ¥è¶³ãƒãƒ¼ã‚¿ãƒ«',
        'TikTok Shopãƒãƒã‚¿ã‚¤ã‚ºè¬›åº§ãƒ­ãƒ¼ãƒ³ãƒ',
        'AI Brain çŸ¥è­˜ãƒ™ãƒ¼ã‚¹'
    ],
    'äº‹æ¥­': [
        'æ–°è¦äº‹æ¥­_Monthlyä¼šè­°',
        'é‹ç”¨ä»£è¡Œ',
        'AIæ•™è‚²äº‹æ¥­',
        'Mrs.PROTEIN',
        'ãƒ€ã‚¤ã‚¨ãƒƒãƒˆäº‹æ¥­',
        'ã‚¢ã‚¤ãƒ¬ãƒãƒ¼ãƒˆ',
        'å–¶æ¥­ä»£è¡Œäº‹æ¥­',
        'ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚¹ã‚¯ãƒ¼ãƒ«äº‹æ¥­',  # APIã‹ã‚‰ç¢ºèªã—ãŸæ­£å¼åç§°
        'TikTokãƒ©ã‚¤ãƒ–ã‚¹ã‚¯ãƒ¼ãƒ«',
        'å„äº‹æ¥­è¨ˆç”»',
        'UGC'
    ],
    'ãƒãƒ‹ãƒ¥ã‚¢ãƒ«': [
        'æ¡ç”¨æ±ºå®šå¾Œã®ãƒ•ãƒ­ãƒ¼ (New)',
        'æ¥­å‹™å¯¾å¿œãƒãƒ‹ãƒ¥ã‚¢ãƒ«',
        'ãƒŠãƒ¬ãƒƒã‚¸å…±æœ‰',
        'é€±æ¬¡/æœˆæ¬¡å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ',
        'SnsClubè¬›å¸«ç´¹ä»‹åˆ¶åº¦ã«ã¤ã„ã¦'
    ],
    'ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹': [
        'æ•™ææ ¼ç´åº«',
        'AIã‚¹ã‚¯ãƒ¼ãƒ«ç”¨å‹•ç”»',
        'AIæ´»ç”¨äº‹ä¾‹ãƒŠãƒ¬ãƒƒã‚¸DB',
        'é–‹ç™ºãƒ„ãƒ¼ãƒ«'
    ],
    'ãã®ä»–': [
        'ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ã®å ±é…¬è¨­å®š',
        'ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ¡ãƒ³ãƒãƒ¼å‹Ÿé›†'
    ]
}

# é †åºã‚’ä¿æŒã™ã‚‹ãŸã‚ã«OrderedDictã®ã‚ˆã†ã«æ‰±ã†
SECTION_ORDER = ['Levelaå…¨ä½“', 'éƒ¨ç½²', 'äº‹æ¥­', 'ãƒãƒ‹ãƒ¥ã‚¢ãƒ«', 'ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹', 'ãã®ä»–']


def organize_by_sections(root_children):
    """Notionã®ç”»é¢æ§‹æˆã«åŸºã¥ã„ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†é¡"""
    # ãƒãƒ¼ãƒ‰åã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
    node_index = {node['name']: node for node in root_children}

    organized = []

    for section_name, items in SECTIONS.items():
        section_node = {
            'name': section_name,
            'type': 'section',
            'children': []
        }

        for item_name in items:
            if item_name in node_index:
                section_node['children'].append(node_index[item_name])

        if section_node['children']:
            organized.append(section_node)

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å«ã¾ã‚Œãªã„ãƒãƒ¼ãƒ‰ã‚’ã€Œãã®ä»–ã€ã«è¿½åŠ 
    categorized = set()
    for items in SECTIONS.values():
        categorized.update(items)

    other_items = [node for node in root_children if node['name'] not in categorized]
    if other_items:
        # æ—¢å­˜ã®ã€Œãã®ä»–ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        other_section = next((s for s in organized if s['name'] == 'ãã®ä»–'), None)
        if other_section:
            other_section['children'].extend(other_items)
        else:
            organized.append({
                'name': 'ãã®ä»–',
                'type': 'section',
                'children': other_items
            })

    return organized


def generate_html(tree_data, template_path, output_path):
    """ãƒ„ãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’HTMLã«åŸ‹ã‚è¾¼ã¿"""
    with open(template_path, 'r', encoding='utf-8') as f:
        html = f.read()

    # JSONå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã¿
    json_data = json.dumps(tree_data, ensure_ascii=False, indent=2)
    html = html.replace('TREE_DATA_PLACEHOLDER', json_data)

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html)

    return output_path


if __name__ == "__main__":
    txt_path = "/Users/hatakiyoto/-AI-egent-libvela/notion_data/pages/notion_hierarchy_tree.txt"
    template_path = "/Users/hatakiyoto/-AI-egent-libvela/notion_data/viewer/family-tree.html"
    output_path = "/Users/hatakiyoto/-AI-egent-libvela/notion_data/viewer/family-tree-view.html"

    print("Parsing hierarchy tree...")
    root_children = parse_tree_txt(txt_path)
    print(f"Found {len(root_children)} top-level items")

    print("Organizing by sections...")
    organized = organize_by_sections(root_children)
    print(f"Created {len(organized)} sections")

    for section in organized:
        children_count = len(section.get('children', []))
        print(f"  - {section['name']}: {children_count} items")

    print("Generating HTML...")
    output = generate_html(organized, template_path, output_path)
    print(f"Saved to: {output}")
